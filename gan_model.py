# -*- coding: utf-8 -*-
"""GAN model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q-ryoQR-K-WyBn53eImjbK0rIJ8YkUFH
"""

import cv2
import numpy as np

# Function to preprocess the input video
def preprocess_video(video_file, frames_per_second, video_duration):
    # Open the video file
    cap = cv2.VideoCapture(video_file)

    # Initialize an empty list to store frames
    frames = []

    # Read frames from the video file
    while(cap.isOpened()):
        ret, frame = cap.read()
        if ret:
            # Resize frame to a fixed resolution (e.g., 64x64)
            frame = cv2.resize(frame, (64, 64))
            # Normalize pixel values to the range [0, 255]
            frame = frame.astype(np.float32)
            # Append frame to the list
            frames.append(frame)
        else:
            break

    # Release the video capture object
    cap.release()

    # Convert the list of frames to a numpy array
    frames = np.array(frames)

    return frames

# Main
if __name__ == "__main__":
    # Define input parameters
    video_file = '/content/339890357_7512337918850413_8714436372918701559_n.mp4'
    frames_per_second = 30
    video_duration = 3  # seconds

    # Preprocess the input video
    input_data = preprocess_video(video_file, frames_per_second, video_duration)

    print("Input video frames shape:", input_data.shape)

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the generator network
def build_generator(latent_dim, output_shape):
    model = keras.Sequential([
        layers.Dense(128, input_dim=latent_dim, activation='relu'),
        layers.Dense(256, activation='relu'),
        layers.Dense(np.prod(output_shape), activation='sigmoid'),
        layers.Reshape(output_shape)
    ])
    return model

# Define the discriminator network
def build_discriminator(input_shape):
    model = keras.Sequential([
        layers.Flatten(input_shape=input_shape),
        layers.Dense(256, activation='relu'),
        layers.Dense(128, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# Define the GAN model
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = keras.Sequential([generator, discriminator])
    return model

# Define the main function to train the GAN
def train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, input_data):
    for epoch in range(epochs):
        # Generate random noise as input for the generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))

        # Generate fake images from the noise using the generator
        fake_images = generator.predict(noise)

        # Select a random batch of real images from the input data
        idx = np.random.randint(0, input_data.shape[0], batch_size)
        real_images = input_data[idx]

        # Combine real and fake images into a single array
        X = np.concatenate([real_images, fake_images])

        # Create labels for the discriminator (1 for real images, 0 for fake images)
        y = np.zeros(2 * batch_size)
        y[:batch_size] = 1

        # Train the discriminator on the combined dataset
        discriminator.trainable = True
        discriminator.train_on_batch(X, y)

        # Generate new random noise for the generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))

        # Create labels for the generator (1 for real images to trick the discriminator)
        misleading_labels = np.ones(batch_size)

        # Freeze the discriminator's weights during generator training
        discriminator.trainable = False

        # Train the generator to fool the discriminator
        gan.train_on_batch(noise, misleading_labels)

        # Print the progress every few epochs
        if epoch % 100 == 0:
            print(f"Epoch: {epoch}")

# Main
if __name__ == "__main__":
    # Define input parameters
    latent_dim = 100
    batch_size = 32
    epochs = 2500

    # Get input shape
    input_shape = input_data.shape[1:]

    # Build and compile the discriminator
    discriminator = build_discriminator(input_shape)
    discriminator.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')

    # Build the generator
    generator = build_generator(latent_dim, input_shape)

    # Build and compile the GAN
    gan = build_gan(generator, discriminator)
    gan.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')

    # Train the GAN
    train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, input_data)

# Generate frames using the trained generator model
def generate_frames(generator, latent_dim, num_frames):
    # Generate random noise as input for the generator
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate frames using the generator
    generated_frames = generator.predict(noise)

    # Optionally post-process the generated frames
    # For example, denormalize pixel values if needed

    return generated_frames

# Main
if __name__ == "__main__":
    # Define input parameters
    num_frames = 90  # Number of frames to generate
    latent_dim = 100  # Latent dimension size

    # Generate frames using the trained generator
    generated_frames = generate_frames(generator, latent_dim, num_frames)

    # Optionally post-process the generated frames

    # Assemble frames into a video using OpenCV
    # Code to assemble frames into a video goes here

import cv2

# Function to assemble frames into a video
def assemble_video(frames, output_video_path, frames_per_second):
    # OpenCV video writer object
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    height, width, _ = frames[0].shape
    video_writer = cv2.VideoWriter(output_video_path, fourcc, frames_per_second, (width, height))

    # Write each frame to the video
    for frame in frames:
        # Convert frame to 8-bit unsigned integers
        frame_uint8 = (frame * 255).astype('uint8')
        video_writer.write(frame_uint8)

    # Release the video writer object
    video_writer.release()

# Main
if __name__ == "__main__":
    # Define input parameters
    output_video_path = 'generated_video.mp4'
    frames_per_second = 30  # Adjust according to your preference

    # Assemble frames into a video
    assemble_video(generated_frames, output_video_path, frames_per_second)

import cv2

# Function to assemble frames into a video
def assemble_video(frames, output_video_path, frames_per_second):
    # OpenCV video writer object
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    height, width, _ = frames[0].shape
    video_writer = cv2.VideoWriter(output_video_path, fourcc, frames_per_second, (width, height))

    # Write each frame to the video
    for i, frame in enumerate(frames):
        # Convert frame to 8-bit unsigned integers
        frame_uint8 = (frame * 255).astype('uint8')
        video_writer.write(frame_uint8)
        print(f"Frame {i+1}/{len(frames)} written to video.")

    # Release the video writer object
    video_writer.release()
    print("Video writing complete.")

# Main
if __name__ == "__main__":
    # Define input parameters
    output_video_path = 'generated_video.mp4'
    frames_per_second = 30  # Adjust according to your preference

    # Assemble frames into a video
    assemble_video(generated_frames, output_video_path, frames_per_second)

import cv2

# Function to preprocess the input video
def preprocess_video(video_path, frames_per_second, video_duration):
    # Open the video file
    video_capture = cv2.VideoCapture(video_path)

    # Initialize an empty list to store video frames
    frames = []

    # Read frames from the video until end or specified duration
    current_frame = 0
    while video_capture.isOpened() and current_frame < frames_per_second * video_duration:
        ret, frame = video_capture.read()
        if ret:
            # Resize frame to desired dimensions (e.g., 64x64)
            frame = cv2.resize(frame, (64, 64))
            # Convert frame to RGB format
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            # Normalize pixel values to range [0, 1]
            frame = frame / 255.0
            # Append frame to the list
            frames.append(frame)
            current_frame += 1
        else:
            break

    # Release the video capture object
    video_capture.release()

    # Convert list of frames to numpy array
    frames = np.array(frames)

    return frames

# Main
if __name__ == "__main__":
    # Define input parameters for preprocessing
    video_path = '/content/339890357_7512337918850413_8714436372918701559_n.mp4'
    frames_per_second = 30
    video_duration = 10  # Duration of video to process (in seconds)

    # Preprocess the input video
    input_data = preprocess_video(video_path, frames_per_second, video_duration)

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the generator network
def build_generator(latent_dim, output_shape):
    model = keras.Sequential([
        layers.Dense(256, input_dim=latent_dim, activation='relu'),
        layers.Reshape((4, 4, 16)),
        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='sigmoid')
    ])
    return model

# Define the discriminator network
def build_discriminator(input_shape):
    model = keras.Sequential([
        layers.Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=input_shape, activation='relu'),
        layers.Conv2D(128, kernel_size=4, strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, kernel_size=4, strides=2, padding='same', activation='relu'),
        layers.Flatten(),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# Define the GAN model
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = keras.Sequential([generator, discriminator])
    return model

# Define the main function to train the GAN
def train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, input_data):
    gan.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')
    for epoch in range(epochs):
        # Generate random noise as input for the generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))

        # Generate fake images from the noise using the generator
        fake_images = generator.predict(noise)

        # Select a random batch of real images from the input data
        idx = np.random.randint(0, input_data.shape[0], batch_size)
        real_images = input_data[idx]

        # Combine real and fake images into a single array
        X = np.concatenate([real_images, fake_images])

        # Create labels for the discriminator (1 for real images, 0 for fake images)
        y = np.zeros(2 * batch_size)
        y[:batch_size] = 1

        # Train the discriminator on the combined dataset
        discriminator.trainable = True
        discriminator.train_on_batch(X, y)

        # Generate new random noise for the generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))

        # Create labels for the generator (1 for real images to trick the discriminator)
        misleading_labels = np.ones(batch_size)

        # Freeze the discriminator's weights during generator training
        discriminator.trainable = False

        # Train the generator to fool the discriminator
        gan.train_on_batch(noise, misleading_labels)

        # Print the progress every few epochs
        if epoch % 100 == 0:
            print(f"Epoch: {epoch}")

# Main
if __name__ == "__main__":
    # Define input parameters
    latent_dim = 100
    batch_size = 32
    epochs = 5000

    # Load and preprocess the input video
    input_data = preprocess_video('/content/339890357_7512337918850413_8714436372918701559_n.mp4')

    # Get input shape
    input_shape = input_data.shape[1:]

    # Build and compile the discriminator
    discriminator = build_discriminator(input_shape)
    discriminator.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')

    # Build the generator
    generator = build_generator(latent_dim, input_shape)

    # Build and compile the GAN
    gan = build_gan(generator, discriminator)

    # Train the GAN
    train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, input_data)

# Define input parameters for preprocessing
video_path = '/content/339890357_7512337918850413_8714436372918701559_n.mp4'
frames_per_second = 30
video_duration = 10  # Duration of video to process (in seconds)

# Preprocess the input video
input_data = preprocess_video(video_path, frames_per_second, video_duration)

# Define input parameters for preprocessing
video_path = '/content/339890357_7512337918850413_8714436372918701559_n.mp4'
frames_per_second = 30
video_duration = 10  # Duration of video to process (in seconds)

# Preprocess the input video
input_data = preprocess_video(video_path, frames_per_second, video_duration)

import cv2

# Function to preprocess the input video
def preprocess_video(video_path, frames_per_second, video_duration):
    # Open the video file
    video_capture = cv2.VideoCapture(video_path)

    # Initialize an empty list to store video frames
    frames = []

    # Read frames from the video until end or specified duration
    current_frame = 0
    while video_capture.isOpened() and current_frame < frames_per_second * video_duration:
        ret, frame = video_capture.read()
        if ret:
            # Resize frame to desired dimensions (e.g., 64x64)
            frame = cv2.resize(frame, (64, 64))
            # Convert frame to RGB format
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            # Normalize pixel values to range [0, 1]
            frame = frame / 255.0
            # Append frame to the list
            frames.append(frame)
            current_frame += 1
        else:
            break

    # Release the video capture object
    video_capture.release()

    # Convert list of frames to numpy array
    frames = np.array(frames)

    return frames

# Main
if __name__ == "__main__":
    # Define input parameters for preprocessing
    video_path = '/content/339890357_7512337918850413_8714436372918701559_n.mp4'
    frames_per_second = 30
    video_duration = 10  # Duration of video to process (in seconds)

    # Preprocess the input video
    input_data = preprocess_video(video_path, frames_per_second, video_duration)

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the generator network
def build_generator(latent_dim, output_shape):
    model = keras.Sequential([
        layers.Dense(256, input_dim=latent_dim, activation='relu'),
        layers.Reshape((4, 4, 16)),
        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='sigmoid')
    ])
    return model

# Define the discriminator network
def build_discriminator(input_shape):
    model = keras.Sequential([
        layers.Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=input_shape, activation='relu'),
        layers.Conv2D(128, kernel_size=4, strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, kernel_size=4, strides=2, padding='same', activation='relu'),
        layers.Flatten(),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# Define the GAN model
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = keras.Sequential([generator, discriminator])
    return model

# Define the main function to train the GAN
def train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, input_data):
    gan.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')
    for epoch in range(epochs):
        # Generate random noise as input for the generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))

        # Generate fake images from the noise using the generator
        fake_images = generator.predict(noise)

        # Select a random batch of real images from the input data
        idx = np.random.randint(0, input_data.shape[0], batch_size)
        real_images = input_data[idx]

        # Combine real and fake images into a single array
        X = np.concatenate([real_images, fake_images])

        # Create labels for the discriminator (1 for real images, 0 for fake images)
        y = np.zeros(2 * batch_size)
        y[:batch_size] = 1

        # Train the discriminator on the combined dataset
        discriminator.trainable = True
        discriminator.train_on_batch(X, y)

        # Generate new random noise for the generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))

        # Create labels for the generator (1 for real images to trick the discriminator)
        misleading_labels = np.ones(batch_size)

        # Freeze the discriminator's weights during generator training
        discriminator.trainable = False

        # Train the generator to fool the discriminator
        gan.train_on_batch(noise, misleading_labels)

        # Print the progress every few epochs
        if epoch % 100 == 0:
            print(f"Epoch: {epoch}")

# Main
if __name__ == "__main__":
    # Define input parameters
    latent_dim = 100
    batch_size = 32
    epochs = 5000

    # Load and preprocess the input video
    input_data = preprocess_video(video_path, frames_per_second, video_duration)

    # Get input shape
    input_shape = input_data.shape[1:]

    # Build and compile the discriminator
    discriminator = build_discriminator(input_shape)
    discriminator.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')

    # Build the generator
    generator = build_generator(latent_dim, input_shape)

    # Build and compile the GAN
    gan = build_gan(generator, discriminator)

    # Train the GAN
    train_gan(generator, discriminator, gan, epochs, batch_size, latent_dim, input_data)



import cv2

# Function to preprocess the input video
def preprocess_video(video_path, frames_per_second, video_duration):
    # Open the video file
    video_capture = cv2.VideoCapture(video_path)

    # Initialize an empty list to store video frames
    frames = []

    # Read frames from the video until end or specified duration
    current_frame = 0
    while video_capture.isOpened() and current_frame < frames_per_second * video_duration:
        ret, frame = video_capture.read()
        if ret:
            # Resize frame to desired dimensions (e.g., 32x32)
            frame = cv2.resize(frame, (32, 32))
            # Convert frame to RGB format
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            # Normalize pixel values to range [0, 1]
            frame = frame / 255.0
            # Append frame to the list
            frames.append(frame)
            current_frame += 1
        else:
            break

    # Release the video capture object
    video_capture.release()

    # Convert list of frames to numpy array
    frames = np.array(frames)

    return frames

import numpy as np
import cv2

# Function to generate and save output video
def generate_and_save_video(generator, num_frames=100, output_video_path='output_video.mp4'):
    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Initialize video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, 30, (generated_images.shape[2], generated_images.shape[1]))

    # Write generated frames to video
    for img in generated_images:
        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR
        out.write((img * 255).astype(np.uint8))  # Convert pixel values back to [0, 255] range
    out.release()

# Main
if __name__ == "__main__":
    # Load the trained generator model
    generator = keras.models.load_model('generator_model.h5')

    # Generate and save output video
    generate_and_save_video(generator, num_frames=100, output_video_path='output_video.mp4')

generator = keras.models.load_model('/home/user/models/generator_model.h5')

import cv2

# Function to preprocess the input video
def preprocess_video(video_path, frames_per_second, video_duration):
    # Open the video file
    video_capture = cv2.VideoCapture(video_path)

    # Initialize an empty list to store video frames
    frames = []

    # Read frames from the video until end or specified duration
    current_frame = 0
    while video_capture.isOpened() and current_frame < frames_per_second * video_duration:
        ret, frame = video_capture.read()
        if ret:
            # Resize frame to desired dimensions (e.g., 32x32)
            frame = cv2.resize(frame, (32, 32))
            # Convert frame to RGB format
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            # Normalize pixel values to range [0, 1]
            frame = frame / 255.0
            # Append frame to the list
            frames.append(frame)
            current_frame += 1
        else:
            break

    # Release the video capture object
    video_capture.release()

    # Convert list of frames to numpy array
    frames = np.array(frames)

    return frames

import numpy as np
import matplotlib.pyplot as plt
import cv2

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        plt.imshow(img)
        plt.axis('off')
        plt.savefig(os.path.join(output_dir, f'frame_{i}.png'))
        plt.close()

# Function to save generated frames as a video
def save_video(frames, output_video_path='output_video.mp4', fps=30):
    # Initialize video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frames[0].shape[1], frames[0].shape[0]))

    # Write frames to video
    for frame in frames:
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        out.write(frame_bgr)

    # Release video writer
    out.release()

# Function to check model convergence by plotting loss curves
def plot_loss_curves(discriminator_losses, generator_losses):
    plt.plot(discriminator_losses, label='Discriminator Loss')
    plt.plot(generator_losses, label='Generator Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('GAN Training Loss')
    plt.legend()
    plt.show()

# Main
if __name__ == "__main__":
    # Assuming you have trained generator, discriminator, and their losses
    # generator, discriminator = train_gan(...)
    # discriminator_losses, generator_losses = train_gan(...)

    # Check model convergence
    plot_loss_curves(discriminator_losses, generator_losses)

    # Verify generator output
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

    # Save generated frames as a video
    # frames = load_generated_frames('output_frames/')
    # save_video(frames, output_video_path='output_video.mp4', fps=30)

import numpy as np
import matplotlib.pyplot as plt
import cv2
import os

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        plt.imshow(img)
        plt.axis('off')
        plt.savefig(os.path.join(output_dir, f'frame_{i}.png'))
        plt.close()

# Function to save generated frames as a video
def save_video(frames, output_video_path='output_video.mp4', fps=30):
    # Initialize video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frames[0].shape[1], frames[0].shape[0]))

    # Write frames to video
    for frame in frames:
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        out.write(frame_bgr)

    # Release video writer
    out.release()

# Function to check model convergence by plotting loss curves
def plot_loss_curves(discriminator_losses, generator_losses):
    plt.plot(discriminator_losses, label='Discriminator Loss')
    plt.plot(generator_losses, label='Generator Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('GAN Training Loss')
    plt.legend()
    plt.show()

# Main
if __name__ == "__main__":
    # Sample placeholder data (replace with actual data)
    discriminator_losses = [0.5, 0.4, 0.3, 0.2, 0.1]
    generator_losses = [1.0, 0.9, 0.8, 0.7, 0.6]

    # Check model convergence
    plot_loss_curves(discriminator_losses, generator_losses)

    # Verify generator output
    # Assuming you have trained generator model
    # generator = train_generator(...)
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

    # Save generated frames as a video
    # frames = load_generated_frames('output_frames/')
    # save_video(frames, output_video_path='output_video.mp4', fps=30)

# Assuming you have trained generator model
# generator = train_generator(...)

# Verify generator output
generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

# Assuming you have loaded the generated frames
# frames = load_generated_frames('output_frames/')

# Save generated frames as a video
save_video(frames, output_video_path='output_video.mp4', fps=30)

import numpy as np
import cv2
import os

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to save generated frames as a video
def save_video(frames, output_video_path='output_video.mp4', fps=30):
    # Initialize video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frames[0].shape[1], frames[0].shape[0]))

    # Write frames to video
    for frame in frames:
        out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))

    # Release video writer
    out.release()

# Main
if __name__ == "__main__":
    # Sample code assuming you have trained generator model
    # generator = train_generator(...)

    # Verify generator output
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

    # Load generated frames
    frames = []
    for i in range(10):
        img = cv2.imread(f'output_frames/frame_{i}.png')
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        frames.append(img)

    # Save generated frames as a video
    save_video(frames, output_video_path='output_video.mp4', fps=30)

import numpy as np
import cv2
import os

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i:04d}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to assemble frames into a video
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', fps=30):
    # Get the list of image files
    image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
    image_files.sort()

    # Read the images and assemble them into video
    frames = []
    for img_file in image_files:
        img = cv2.imread(os.path.join(input_dir, img_file))
        frames.append(img)

    # Initialize video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frames[0].shape[1], frames[0].shape[0]))

    # Write frames to video
    for frame in frames:
        out.write(frame)

    # Release video writer
    out.release()

# Main
if __name__ == "__main__":
    # Sample code assuming you have trained generator model
    # generator = train_generator(...)

    # Verify generator output and save frames as images
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

    # Assemble frames into video
    frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', fps=30)

import numpy as np
import cv2
import os

# Assuming you have trained generator model
# generator = train_generator(...)

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i:04d}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to assemble frames into a video
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', fps=30):
    # Get the list of image files
    image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
    image_files.sort()

    # Read the images and assemble them into video
    frames = []
    for img_file in image_files:
        img = cv2.imread(os.path.join(input_dir, img_file))
        frames.append(img)

    # Initialize video writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frames[0].shape[1], frames[0].shape[0]))

    # Write frames to video
    for frame in frames:
        out.write(frame)

    # Release video writer
    out.release()

# Main
if __name__ == "__main__":
    # Verify generator output and save frames as images
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

    # Assemble frames into video
    frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', fps=30)

import numpy as np
import cv2
import os

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i:04d}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to assemble frames into a video
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', fps=30):
    try:
        # Get the list of image files
        image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
        image_files.sort()

        # Check if there are any frames to process
        if not image_files:
            print("No image files found in the input directory.")
            return

        # Read the images and assemble them into video
        frames = []
        for img_file in image_files:
            img = cv2.imread(os.path.join(input_dir, img_file))
            frames.append(img)

        # Initialize video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frames[0].shape[1], frames[0].shape[0]))

        # Write frames to video
        for frame in frames:
            out.write(frame)

        # Release video writer
        out.release()

        print("Video saved successfully:", output_video_path)

    except Exception as e:
        print("Error occurred while creating the video:", str(e))

# Main
if __name__ == "__main__":
    # Verify generator output and save frames as images
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

    # Assemble frames into video
    frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', fps=30)



import numpy as np
import cv2
import os

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i:04d}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to assemble frames into a video
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', fps=30, resolution=(1920, 1080)):
    try:
        # Get the list of image files
        image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
        image_files.sort()

        # Check if there are any frames to process
        if not image_files:
            print("No image files found in the input directory.")
            return

        # Read the images and assemble them into video
        frames = []
        for img_file in image_files:
            img = cv2.imread(os.path.join(input_dir, img_file))
            img = cv2.resize(img, resolution)  # Resize the image to desired resolution
            frames.append(img)

        # Initialize video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, resolution)

        # Write frames to video
        for frame in frames:
            out.write(frame)

        # Release video writer
        out.release()

        print("Video saved successfully:", output_video_path)

    except Exception as e:
        print("Error occurred while creating the video:", str(e))

# Main
if __name__ == "__main__":
    # Verify generator output and save frames as images
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

    # Assemble frames into video with 1080p resolution
    frames_to_video(input_dir='output_frames/', output_video_path='output_video_1080p.mp4', fps=30, resolution=(1920, 1080))

import numpy as np
import cv2
import os

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i:04d}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to assemble frames into a video
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', fps=30, resolution=(3840, 2160), codec='mp4v', bitrate=4000000):
    try:
        # Get the list of image files
        image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
        image_files.sort()

        # Check if there are any frames to process
        if not image_files:
            print("No image files found in the input directory.")
            return

        # Read the images and assemble them into video
        frames = []
        for img_file in image_files:
            img = cv2.imread(os.path.join(input_dir, img_file))
            img = cv2.resize(img, resolution)  # Resize the image to desired resolution
            frames.append(img)

        # Initialize video writer
        fourcc = cv2.VideoWriter_fourcc(*codec)
        out = cv2.VideoWriter(output_video_path, fourcc, fps, resolution)

        # Write frames to video
        for frame in frames:
            out.write(frame)

        # Release video writer
        out.release()

        print("Video saved successfully:", output_video_path)

    except Exception as e:
        print("Error occurred while creating the video:", str(e))

# Main
if __name__ == "__main__":
    # Verify generator output and save frames as images
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

    # Assemble frames into video with 4K resolution and high bitrate
    frames_to_video(input_dir='output_frames/', output_video_path='output_video_4k.mp4', fps=60, resolution=(3840, 2160), codec='mp4v', bitrate=80000000)

import cv2
import os

# Function to extract video parameters
def get_video_parameters(input_video_path):
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened():
        print("Error: Unable to open input video.")
        return None

    # Get video parameters
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    codec = int(cap.get(cv2.CAP_PROP_FOURCC))
    bitrate = int(cap.get(cv2.CAP_PROP_BITRATE))

    cap.release()

    return fps, (width, height), codec, bitrate

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i:04d}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to assemble frames into a video with input video parameters
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', input_video_path=None):
    try:
        # Get input video parameters
        if input_video_path:
            fps, resolution, codec, bitrate = get_video_parameters(input_video_path)
        else:
            # Default parameters if input video path is not provided
            fps, resolution, codec, bitrate = 30, (1920, 1080), cv2.VideoWriter_fourcc(*'mp4v'), 8000000

        # Get the list of image files
        image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
        image_files.sort()

        # Check if there are any frames to process
        if not image_files:
            print("No image files found in the input directory.")
            return

        # Read the images and assemble them into video
        frames = []
        for img_file in image_files:
            img = cv2.imread(os.path.join(input_dir, img_file))
            img = cv2.resize(img, resolution)  # Resize the image to input video resolution
            frames.append(img)

        # Initialize video writer with input video parameters
        out = cv2.VideoWriter(output_video_path, codec, fps, resolution)

        # Write frames to video
        for frame in frames:
            out.write(frame)

        # Release video writer
        out.release()

        print("Video saved successfully:", output_video_path)

    except Exception as e:
        print("Error occurred while creating the video:", str(e))

# Main
if __name__ == "__main__":
    # Example usage: specify input video path if available
    input_video_path = 'input_video.mp4'  # Update with your input video path
    generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')
    frames_to_video(input_dir='output_frames/', output_video_path='output_video_same_quality.mp4', input_video_path=input_video_path)

import cv2
import os

# Function to extract video parameters
def get_video_parameters(input_video_path):
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened():
        print("Error: Unable to open input video.")
        return None

    # Get video parameters
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    codec = int(cap.get(cv2.CAP_PROP_FOURCC))
    bitrate = int(cap.get(cv2.CAP_PROP_BITRATE))

    cap.release()

    return fps, (width, height), codec, bitrate

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i:04d}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to assemble frames into a video with input video parameters
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', input_video_path=None):
    try:
        # Get input video parameters
        if input_video_path:
            fps, resolution, codec, bitrate = get_video_parameters(input_video_path)
        else:
            # Default parameters if input video path is not provided
            fps, resolution, codec, bitrate = 30, (1920, 1080), cv2.VideoWriter_fourcc(*'mp4v'), 8000000

        # Get the list of image files
        image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
        image_files.sort()

        # Check if there are any frames to process
        if not image_files:
            print("No image files found in the input directory.")
            return

        # Read the images and assemble them into video
        frames = []
        for img_file in image_files:
            img = cv2.imread(os.path.join(input_dir, img_file))
            img = cv2.resize(img, resolution)  # Resize the image to input video resolution
            frames.append(img)

        # Initialize video writer with input video parameters
        out = cv2.VideoWriter(output_video_path, codec, fps, resolution)

        # Write frames to video
        for frame in frames:
            out.write(frame)

        # Release video writer
        out.release()

        print("Video saved successfully:", output_video_path)

    except Exception as e:
        print("Error occurred while creating the video:", str(e))

# Main
if __name__ == "__main__":
    # Example usage: specify input video path if available
    input_video_path = 'input_video.mp4'  # Update with your input video path
    if os.path.exists(input_video_path):
        generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')
        frames_to_video(input_dir='output_frames/', output_video_path='output_video_same_quality.mp4', input_video_path=input_video_path)
    else:
        print("Input video file not found.")

import os
import cv2
import numpy as np

# Function to locate input video file
def find_input_video():
    # Add code here to locate the input video file
    input_video_path = '/content/339890357_7512337918850413_8714436372918701559_n.mp4'  # Update with the path to your input video file
    if os.path.exists(input_video_path):
        return input_video_path
    else:
        print("Input video file not found.")
        return None

# Function to extract video parameters
def get_video_parameters(input_video_path):
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened():
        print("Error: Unable to open input video.")
        return None

    # Get video parameters
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    codec = int(cap.get(cv2.CAP_PROP_FOURCC))
    bitrate = int(cap.get(cv2.CAP_PROP_BITRATE))

    cap.release()

    return fps, (width, height), codec, bitrate

# Function to generate and save output frames
def generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/'):
    os.makedirs(output_dir, exist_ok=True)

    # Generate random noise vectors
    latent_dim = 100  # Example latent dimension size
    noise = np.random.normal(0, 1, (num_frames, latent_dim))

    # Generate fake images using the generator
    generated_images = generator.predict(noise)

    # Save generated frames as images
    for i, img in enumerate(generated_images):
        # Convert image to uint8 format
        img = (img * 255).astype(np.uint8)
        cv2.imwrite(os.path.join(output_dir, f'frame_{i:04d}.png'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

# Function to assemble frames into a video with input video parameters
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', input_video_path=None):
    try:
        # Get input video parameters
        if input_video_path:
            fps, resolution, codec, bitrate = get_video_parameters(input_video_path)
        else:
            # Default parameters if input video path is not provided
            fps, resolution, codec, bitrate = 30, (1920, 1080), cv2.VideoWriter_fourcc(*'mp4v'), 8000000

        # Get the list of image files
        image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
        image_files.sort()

        # Check if there are any frames to process
        if not image_files:
            print("No image files found in the input directory.")
            return

        # Read the images and assemble them into video
        frames = []
        for img_file in image_files:
            img = cv2.imread(os.path.join(input_dir, img_file))
            img = cv2.resize(img, resolution)  # Resize the image to input video resolution
            frames.append(img)

        # Initialize video writer with input video parameters
        out = cv2.VideoWriter(output_video_path, codec, fps, resolution)

        # Write frames to video
        for frame in frames:
            out.write(frame)

        # Release video writer
        out.release()

        print("Video saved successfully:", output_video_path)

    except Exception as e:
        print("Error occurred while creating the video:", str(e))

# Main
if __name__ == "__main__":
    # Locate input video file
    input_video_path = find_input_video()
    if input_video_path:
        # Generate and save frames using GAN generator
        # Example usage: generate_and_save_frames(generator, num_frames=10, output_dir='output_frames/')

        # Assemble frames into video with input video parameters
        frames_to_video(input_dir='output_frames/', output_video_path='output_video_same_quality.mp4', input_video_path=input_video_path)

import cv2
import os

# Function to assemble frames into a video with input video parameters
def frames_to_video(input_dir='output_frames/', output_video_path='output_video.mp4', input_video_path=None):
    try:
        # Get input video parameters
        if input_video_path:
            cap = cv2.VideoCapture(input_video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            codec = int(cap.get(cv2.CAP_PROP_FOURCC))
            cap.release()
        else:
            # Default parameters if input video path is not provided
            fps, width, height, codec = 30, 1920, 1080, cv2.VideoWriter_fourcc(*'mp4v')

        # Get the list of image files
        image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]
        image_files.sort()

        # Check if there are any frames to process
        if not image_files:
            print("No image files found in the input directory.")
            return

        # Initialize video writer with input video parameters
        out = cv2.VideoWriter(output_video_path, codec, fps, (width, height))

        # Write frames to video
        for img_file in image_files:
            img = cv2.imread(os.path.join(input_dir, img_file))
            out.write(img)

        # Release video writer
        out.release()

        print("Video saved successfully:", output_video_path)

    except Exception as e:
        print("Error occurred while creating the video:", str(e))

# Main
if __name__ == "__main__":
    input_video_path = '/content/339890357_7512337918850413_8714436372918701559_n.mp4'  # Update with your input video path
    output_video_path = 'output_video_same_quality.mp4'  # Update with desired output video path
    frames_to_video(input_dir='output_frames/', output_video_path=output_video_path, input_video_path=input_video_path)



input_video_path = '/content/339890357_7512337918850413_8714436372918701559_n.mp4'