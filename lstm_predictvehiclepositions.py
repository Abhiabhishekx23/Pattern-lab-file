# -*- coding: utf-8 -*-
"""LSTM predictvehiclepositions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gQEK5S7aA9Dt6KKEcJUk17MfloaOMo7-
"""

import cv2
import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense

def extract_features(frame):
    features = np.random.rand(1, num_features)
    return features


def process_video(video_path):
    cap = cv2.VideoCapture(video_path)
    features_sequence = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        features = extract_features(frame)
        features_sequence.append(features)
    cap.release()
    return np.array(features_sequence)


num_features = 10
n_timesteps = 10


video_path = '/content/istockphoto-1665784267-640_adpp_is.mp4'
features_sequence = process_video(video_path)


if len(features_sequence) < n_timesteps:
    features_sequence = np.pad(features_sequence, ((0, n_timesteps - len(features_sequence)), (0, 0)), 'constant')
else:
    features_sequence = features_sequence[:n_timesteps]


X = features_sequence.reshape(1, n_timesteps, num_features)


model = Sequential()
model.add(LSTM(50, input_shape=(n_timesteps, num_features), return_sequences=True))
model.add(Dense(2))
model.compile(loss='mean_squared_error', optimizer='adam')


predicted_future_positions = model.predict(X)

print("Predicted Future Positions:")
print(predicted_future_positions)

import cv2
import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense


def extract_features(frame):


    features = np.random.rand(num_features)
    return features


def process_video(video_path, window_size, stride):
    cap = cv2.VideoCapture(video_path)
    features_sequence = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        features = extract_features(frame)
        features_sequence.append(features)
    cap.release()


    windows = []
    for i in range(0, len(features_sequence) - window_size + 1, stride):
        window = features_sequence[i:i+window_size]
        windows.append(window)

    return np.array(windows)


num_features = 10
window_size = 10
stride = 5


video_path = '/content/istockphoto-1665784267-640_adpp_is.mp4'
windows = process_video(video_path, window_size, stride)


model = Sequential()
model.add(LSTM(50, input_shape=(window_size, num_features), return_sequences=True))
model.add(Dense(2))
model.compile(loss='mean_squared_error', optimizer='adam')


predicted_positions = []
for window in windows:
    X = window.reshape(1, window_size, num_features)
    predicted_positions.append(model.predict(X))


for i, positions in enumerate(predicted_positions):
    print(f"Window {i}:")
    for j, pos in enumerate(positions):
        print(f"Vehicle {j}: Predicted Position: {pos}")

import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense

def extract_color_features(frame):
    color_features = np.random.rand(num_colors)
    return color_features

def extract_position_features(frame):
    position_features = np.random.rand(num_positions)
    return position_features

def process_video(video_path):


    num_frames = 100
    num_vehicles = 5
    num_colors = 5
    num_positions = 2

    color_sequences = [np.random.rand(num_frames, num_colors) for _ in range(num_vehicles)]
    position_sequences = [np.random.rand(num_frames, num_positions) for _ in range(num_vehicles)]

    return color_sequences, position_sequences

num_colors = 5
num_positions = 2
n_timesteps = 10

video_path = '/content/istockphoto-1665784267-640_adpp_is.mp4'
color_sequences, position_sequences = process_video(video_path)

input_sequences = []
for color_seq, pos_seq in zip(color_sequences, position_sequences):
    combined_seq = np.concatenate((color_seq, pos_seq), axis=1)
    input_sequences.append(combined_seq)

input_sequences = np.array(input_sequences)

model = Sequential()
model.add(LSTM(50, input_shape=(n_timesteps, num_colors + num_positions), return_sequences=True))
model.add(Dense(num_positions))
model.compile(loss='mean_squared_error', optimizer='adam')

for input_seq in input_sequences:
    if input_seq.shape[0] >= n_timesteps:
        X = input_seq[:n_timesteps, :]
    else:
        X = np.pad(input_seq, ((0, n_timesteps - input_seq.shape[0]), (0, 0)), 'constant')
    X = X.reshape(1, n_timesteps, num_colors + num_positions)
    predicted_positions = model.predict(X)
    print("Predicted Future Positions for Color:", predicted_positions)